<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>An Overview of Visual Cortex | Diaaaooo's</title><meta name=keywords content="Visual Cortex,Computer Vision"><meta name=description content="I like to dig deep into the origin to learn how one thing evolved to its current state when I learn something new. To learn about computer vision, one has to understand Convolutional Neural Network, short for “CNN”. And to fully understand convolutional neural networks, we have to look back to its origin - Visual Cortex.
I am not an expert of the structure of human eyes or how the visual system works."><meta name=author content="Diao"><link rel=canonical href=https://canonical.url/to/page><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U+6hYRq/Ez/nm5vg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://diaaaooo.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://diaaaooo.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://diaaaooo.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://diaaaooo.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://diaaaooo.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="An Overview of Visual Cortex"><meta property="og:description" content="I like to dig deep into the origin to learn how one thing evolved to its current state when I learn something new. To learn about computer vision, one has to understand Convolutional Neural Network, short for “CNN”. And to fully understand convolutional neural networks, we have to look back to its origin - Visual Cortex.
I am not an expert of the structure of human eyes or how the visual system works."><meta property="og:type" content="article"><meta property="og:url" content="https://diaaaooo.github.io/posts/1-an-overview-of-visual-cortex/1-an-overview-of-visual-cortex/"><meta property="og:image" content="https://diaaaooo.github.io/%3Cimage%20path/url%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-09-07T00:00:00+00:00"><meta property="article:modified_time" content="2023-09-07T00:00:00+00:00"><meta property="og:site_name" content="Diaaaooo's"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://diaaaooo.github.io/%3Cimage%20path/url%3E"><meta name=twitter:title content="An Overview of Visual Cortex"><meta name=twitter:description content="I like to dig deep into the origin to learn how one thing evolved to its current state when I learn something new. To learn about computer vision, one has to understand Convolutional Neural Network, short for “CNN”. And to fully understand convolutional neural networks, we have to look back to its origin - Visual Cortex.
I am not an expert of the structure of human eyes or how the visual system works."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://diaaaooo.github.io/posts/"},{"@type":"ListItem","position":2,"name":"An Overview of Visual Cortex","item":"https://diaaaooo.github.io/posts/1-an-overview-of-visual-cortex/1-an-overview-of-visual-cortex/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"An Overview of Visual Cortex","name":"An Overview of Visual Cortex","description":"I like to dig deep into the origin to learn how one thing evolved to its current state when I learn something new. To learn about computer vision, one has to understand Convolutional Neural Network, short for “CNN”. And to fully understand convolutional neural networks, we have to look back to its origin - Visual Cortex.\nI am not an expert of the structure of human eyes or how the visual system works.","keywords":["Visual Cortex","Computer Vision"],"articleBody":"I like to dig deep into the origin to learn how one thing evolved to its current state when I learn something new. To learn about computer vision, one has to understand Convolutional Neural Network, short for “CNN”. And to fully understand convolutional neural networks, we have to look back to its origin - Visual Cortex.\nI am not an expert of the structure of human eyes or how the visual system works. But I will try my best to explain what I learned about the human visual cortex from reading papers and how it is connected to the structure of convolutional neural networks.\nBasic Terminology These are the unavoidable terms that you will see in a paper involving the visual cortex.\nCortex By definition, cortex means the outer layer of a structure or organ.\nCerebral Cortex In the context of the brain, the cerebral cortex, also known as the neocortex, specifically refers to the outermost layer of the brain’s cerebrum. It’s responsible for higher cognitive functions, including sensory processing (vision, hearing, touch and proprioception, taste and smell), motor control, language processing, perception and attention (object recognition, face recognition, scene analysis), memory and more.\nOccipital Lobe Occipital lobe is a region of the cerebral cortex located at the back of the brain, responsible for processing visual information. It handles visual processing (color, shape, motion), visual perception (transform into meaningful visual experiences), object recognition (recognize and identify), spatial awareness (object location, contribute to judging distance to some extent, particularly in the context of depth perception), motion detection (object movement) and more.\nVentral Stream Ventral stream is the “what pathway” located in the occipital lobe. It is the pathway for visual inputs processing, object detection and recognition. It is usually considered the inspiration of the design of convolutional neural networks.\nDorsal Stream Dorsal stream is the “where pathway” located in the parietal lobe which is adjacent to the occipital lobe. It is the pathway for spatial perception and motor control. It is so crucial to object detection and recognition, especially in spatial perception, that we cannot ignore it while trying to understand how the visual cortex works.\nFig. 1. Illustration of the two pathways: ventral stream and dorsal stream. (Image source: By Selket - I (Selket) made this from File:Gray728.svg, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=1679336.)\nRelevant Ventral Stream Components Ventral stream is far more complex than what I can explain. Since we are aiming to understand its connection to CNN, I’ll only cover the components of the ventral stream that I think are relevant to the structure of convolutional neural networks.\nV1 The primary visual cortex, short for V1, extracts low-level information from the visual input, such as edges, colors, and orientations.\nV2 The secondary visual cortex, short for V2, continues to process basic visual features by extracting more-complex features like shapes and textures, as well as in the detection of motion.\nV3 The third visual cortex, short for V3, analyzes motion, orientation, and basic spatial information.\nV4 This fourth visual cortex, short for V4, is specialized in color perception, shape processing, the section of object boundaries, and is sensitive to color constancy (the ability to perceive color despite changes in lighting conditions).\nIT Cortex The inferotemporal cortex, short for IT cortex, is specialized for object recognition and identification, as well as associates objects with memories to assign meanings and contextual information.\nVisual Information Flow All papers pointed me back to this original research about how visual information flows. It proposed that visual information splits into two directions after arriving in the retina: ventral stream (the “what” pathway) and dorsal stream (the “where” pathway). Ventral stream focuses on object detection and recognition. Dorsal stream focuses on spatial feature analysis and motor control.\nSince then, the ventral stream information flow was believed to be a feedforward linear architecture specialized for object detection and recognition.\nFeedforward Linear Architecture Visual input accepted by retina flows into V1. V1 extracts low-level information like edges, colors, and orientations then passes the processed information onto V2. V2 extracts more complex information like shapes, textures and detects motion then passes the processed information onto V4. V3 is often left out due to the fact that it is specialized in the analysis of spatial information which is more like a dorsal stream’s thing than ventral stream. V4 receives information from V2 and continues to process higher level information like shapes, object boundaries and lighting then pass the processed information to the IT cortex where neurons handle object recognition and identification. The IT cortex is considered the endpoint of the ventral stream.\nThis biological science paper presented the feedforward linear architecture which looks very similar to a convolutional neural network. The paper also explained why such architecture is supported even though there are local feedback loops and general feedback loops across the entire ventral stream.\nFig. 2. Illustration of the feedforward linear architecture of the human visual cortex system. (Image source: Serre et al. 2007)\nThe ML field also accepted such a belief. This review paper of deep learning models submitted in 2017 proposed one version of explanation. It has become very popular since the citation in this deep learning overview post published in Lilian Weng’s blog. The breakthrough design in Residual Net (ResNet) which allows inputs from one layer to be passed down to two layers after is also associated with the shortcut between V1 and V4. V4 was found to be able to accept information directly from V1.\nFig. 2. Illustration of the human visual cortex system. (Image source: Wang et al. 2017)\nIt offers a very elegant explanation of how CNN and visual cortex are connected and it could certainly be how convolutional neural networks were inspired. But I felt obligated to also look into different opinions and see if the continuous research in the visual cortex field has moved forward and brought up new ideas. It does.\nRecurrent Non-Linear Architecture This cognitive science paper published in 2014 brought up a different perspective since it found more and more studies and research that support its opinion. It challenges that the visual information flow is actually a recurrent non-linear architecture instead of a simple feedforward linear architecture.\nV1 actually sends out processed information to V2, V3, V4 and MT (a component related to memory processing) simultaneously. All other components continuously send feedback back to help correct the processing. The entire visual information flow is a continuous loop with multiple complex loops inside it. All of these contribute to correct object detection and recognition.\nIt can also explain why YOLO is not good at detecting small objects in local regions to a certain extent. Because YOLO lacks components like V3 that handles basic spatial information processes and keeps correcting the main processing stream. This is just my guess though. To investigate the real causes and solutions, I would need to learn more about how human’s visual system extracts depth information solely from visual inputs and how it can be implemented in ML.\nCitation Cited as:\nDiao, He. (Sep 2023). “An Overview of Visual Cortex.” Diaaaooo’s Post:https://diaaaooo.github.io/posts/1-an-overview-of-visual-cortex/.\nReferences [1] Ungerleider et al. “Two Cortical Visual Systems.\" NYU (1982)\n[2] Serre et al. “A feedforward architecture accounts for rapid categorization.\" PNAS PNAS:104(15)6424-6429 (2007)\n[3] Wang et al. “On the Origin of Deep Learning.\" arVix preprint arXiv:1702.07800 (2017)\n[4] Weng, Lilian. (Jun 2017). “An Overview of Deep Learning for Curious People”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\n[5] Kravitz et al. “The ventral visual pathway: An expanded neural framework for the processing of object quality.\" NCBI doi: 10.1016/j.tics.2012.10.011 (2014)\n","wordCount":"1251","inLanguage":"en","image":"https://diaaaooo.github.io/%3Cimage%20path/url%3E","datePublished":"2023-09-07T00:00:00Z","dateModified":"2023-09-07T00:00:00Z","author":{"@type":"Person","name":"Diao"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://diaaaooo.github.io/posts/1-an-overview-of-visual-cortex/1-an-overview-of-visual-cortex/"},"publisher":{"@type":"Organization","name":"Diaaaooo's","logo":{"@type":"ImageObject","url":"https://diaaaooo.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://diaaaooo.github.io/ accesskey=h title="Diaaaooo's (Alt + H)"><img src=https://diaaaooo.github.io/apple-touch-icon.png alt aria-label=logo height=35>Diaaaooo's</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://diaaaooo.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://diaaaooo.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://diaaaooo.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://diaaaooo.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://diaaaooo.github.io/posts/>Posts</a></div><h1 class=post-title>An Overview of Visual Cortex</h1><div class=post-meta><span title='2023-09-07 00:00:00 +0000 +0000'>September 7, 2023</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Diao&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/1-an-overview-of-visual-cortex/1-an-overview-of-visual-cortex.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#basic-terminology>Basic Terminology</a><ul><li><a href=#cortex>Cortex</a></li><li><a href=#cerebral-cortex>Cerebral Cortex</a></li><li><a href=#occipital-lobe>Occipital Lobe</a></li><li><a href=#ventral-stream>Ventral Stream</a></li><li><a href=#dorsal-stream>Dorsal Stream</a></li></ul></li><li><a href=#relevant-ventral-stream-components>Relevant Ventral Stream Components</a><ul><li><a href=#v1>V1</a></li><li><a href=#v2>V2</a></li><li><a href=#v3>V3</a></li><li><a href=#v4>V4</a></li><li><a href=#it-cortex>IT Cortex</a></li></ul></li><li><a href=#visual-information-flow>Visual Information Flow</a><ul><li><a href=#feedforward-linear-architecture>Feedforward Linear Architecture</a></li><li><a href=#recurrent-non-linear-architecture>Recurrent Non-Linear Architecture</a></li></ul></li><li><a href=#citation>Citation</a></li><li><a href=#references>References</a></li></ul></nav></div></details></div><div class=post-content><p>I like to dig deep into the origin to learn how one thing evolved to its current state when I learn something new. To learn about computer vision, one has to understand Convolutional Neural Network, short for “CNN”. And to fully understand convolutional neural networks, we have to look back to its origin - Visual Cortex.</p><p>I am not an expert of the structure of human eyes or how the visual system works. But I will try my best to explain what I learned about the human visual cortex from reading papers and how it is connected to the structure of convolutional neural networks.</p><h2 id=basic-terminology>Basic Terminology<a hidden class=anchor aria-hidden=true href=#basic-terminology>#</a></h2><p>These are the unavoidable terms that you will see in a paper involving the visual cortex.</p><h3 id=cortex>Cortex<a hidden class=anchor aria-hidden=true href=#cortex>#</a></h3><p>By definition, cortex means the outer layer of a structure or organ.</p><h3 id=cerebral-cortex>Cerebral Cortex<a hidden class=anchor aria-hidden=true href=#cerebral-cortex>#</a></h3><p>In the context of the brain, the cerebral cortex, also known as the neocortex, specifically refers to the outermost layer of the brain’s cerebrum. It’s responsible for higher cognitive functions, including sensory processing (vision, hearing, touch and proprioception, taste and smell), motor control, language processing, perception and attention (object recognition, face recognition, scene analysis), memory and more.</p><h3 id=occipital-lobe>Occipital Lobe<a hidden class=anchor aria-hidden=true href=#occipital-lobe>#</a></h3><p>Occipital lobe is a region of the cerebral cortex located at the back of the brain, responsible for processing visual information. It handles visual processing (color, shape, motion), visual perception (transform into meaningful visual experiences), object recognition (recognize and identify), spatial awareness (object location, contribute to judging distance to some extent, particularly in the context of depth perception), motion detection (object movement) and more.</p><h3 id=ventral-stream>Ventral Stream<a hidden class=anchor aria-hidden=true href=#ventral-stream>#</a></h3><p>Ventral stream is the “what pathway” located in the occipital lobe. It is the pathway for visual inputs processing, object detection and recognition. It is usually considered the inspiration of the design of convolutional neural networks.</p><h3 id=dorsal-stream>Dorsal Stream<a hidden class=anchor aria-hidden=true href=#dorsal-stream>#</a></h3><p>Dorsal stream is the “where pathway” located in the parietal lobe which is adjacent to the occipital lobe. It is the pathway for spatial perception and motor control. It is so crucial to object detection and recognition, especially in spatial perception, that we cannot ignore it while trying to understand how the visual cortex works.</p><figure class=align-center><img loading=lazy src=/posts/1-an-overview-of-visual-cortex/fig-ventra-stream-and-dorsal-stream.png#center alt="Illustration of the two pathways: ventral stream and dorsal stream."><figcaption><p>Fig. 1. Illustration of the two pathways: ventral stream and dorsal stream. (Image source: By Selket - I (Selket) made this from File:Gray728.svg, CC BY-SA 3.0, <a href="https://commons.wikimedia.org/w/index.php?curid=1679336">https://commons.wikimedia.org/w/index.php?curid=1679336</a>.)</p></figcaption></figure><h2 id=relevant-ventral-stream-components>Relevant Ventral Stream Components<a hidden class=anchor aria-hidden=true href=#relevant-ventral-stream-components>#</a></h2><p>Ventral stream is far more complex than what I can explain. Since we are aiming to understand its connection to CNN, I’ll only cover the components of the ventral stream that I think are relevant to the structure of convolutional neural networks.</p><h3 id=v1>V1<a hidden class=anchor aria-hidden=true href=#v1>#</a></h3><p>The primary visual cortex, short for V1, extracts low-level information from the visual input, such as edges, colors, and orientations.</p><h3 id=v2>V2<a hidden class=anchor aria-hidden=true href=#v2>#</a></h3><p>The secondary visual cortex, short for V2, continues to process basic visual features by extracting more-complex features like shapes and textures, as well as in the detection of motion.</p><h3 id=v3>V3<a hidden class=anchor aria-hidden=true href=#v3>#</a></h3><p>The third visual cortex, short for V3, analyzes motion, orientation, and basic spatial information.</p><h3 id=v4>V4<a hidden class=anchor aria-hidden=true href=#v4>#</a></h3><p>This fourth visual cortex, short for V4, is specialized in color perception, shape processing, the section of object boundaries, and is sensitive to color constancy (the ability to perceive color despite changes in lighting conditions).</p><h3 id=it-cortex>IT Cortex<a hidden class=anchor aria-hidden=true href=#it-cortex>#</a></h3><p>The inferotemporal cortex, short for IT cortex, is specialized for object recognition and identification, as well as associates objects with memories to assign meanings and contextual information.</p><h2 id=visual-information-flow>Visual Information Flow<a hidden class=anchor aria-hidden=true href=#visual-information-flow>#</a></h2><p>All papers pointed me back to <a href=https://www.cns.nyu.edu/~tony/vns/readings/ungerleider-mishkin-1982.pdf>this</a> original research about how visual information flows. It proposed that visual information splits into two directions after arriving in the retina: ventral stream (the “what” pathway) and dorsal stream (the “where” pathway). Ventral stream focuses on object detection and recognition. Dorsal stream focuses on spatial feature analysis and motor control.</p><p>Since then, the ventral stream information flow was believed to be a feedforward linear architecture specialized for object detection and recognition.</p><h3 id=feedforward-linear-architecture>Feedforward Linear Architecture<a hidden class=anchor aria-hidden=true href=#feedforward-linear-architecture>#</a></h3><p>Visual input accepted by retina flows into V1. V1 extracts low-level information like edges, colors, and orientations then passes the processed information onto V2. V2 extracts more complex information like shapes, textures and detects motion then passes the processed information onto V4. V3 is often left out due to the fact that it is specialized in the analysis of spatial information which is more like a dorsal stream’s thing than ventral stream. V4 receives information from V2 and continues to process higher level information like shapes, object boundaries and lighting then pass the processed information to the IT cortex where neurons handle object recognition and identification. The IT cortex is considered the endpoint of the ventral stream.</p><p><a href=https://www.pnas.org/doi/10.1073/pnas.0700622104>This</a> biological science paper presented the feedforward linear architecture which looks very similar to a convolutional neural network. The paper also explained why such architecture is supported even though there are local feedback loops and general feedback loops across the entire ventral stream.</p><figure class=align-center><img loading=lazy src=/posts/1-an-overview-of-visual-cortex/fig-feedforward-linear-architecture-of-the-human-visual-system.png#center alt="Illustration of the feedforward linear architecture of the human visual cortex system."><figcaption><p>Fig. 2. Illustration of the feedforward linear architecture of the human visual cortex system. (Image source: <a href=https://www.pnas.org/doi/10.1073/pnas.0700622104>Serre et al. 2007</a>)</p></figcaption></figure><p>The ML field also accepted such a belief. <a href=https://arxiv.org/abs/1702.07800>This</a> review paper of deep learning models submitted in 2017 proposed one version of explanation. It has become very popular since the citation in <a href=https://lilianweng.github.io/posts/2017-06-21-overview/>this</a> deep learning overview post published in <a href=https://lilianweng.github.io/>Lilian Weng’s blog</a>. The breakthrough design in Residual Net (ResNet) which allows inputs from one layer to be passed down to two layers after is also associated with the shortcut between V1 and V4. V4 was found to be able to accept information directly from V1.</p><figure class=align-center><img loading=lazy src=/posts/1-an-overview-of-visual-cortex/fig-visual-cortex-connection-with-cnn.png#center alt="Illustration of the human visual cortex system."><figcaption><p>Fig. 2. Illustration of the human visual cortex system. (Image source: <a href=https://arxiv.org/abs/1702.07800>Wang et al. 2017</a>)</p></figcaption></figure><p>It offers a very elegant explanation of how CNN and visual cortex are connected and it could certainly be how convolutional neural networks were inspired. But I felt obligated to also look into different opinions and see if the continuous research in the visual cortex field has moved forward and brought up new ideas. It does.</p><h3 id=recurrent-non-linear-architecture>Recurrent Non-Linear Architecture<a hidden class=anchor aria-hidden=true href=#recurrent-non-linear-architecture>#</a></h3><p><a href=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3532569/>This</a> cognitive science paper published in 2014 brought up a different perspective since it found more and more studies and research that support its opinion. It challenges that the visual information flow is actually a recurrent non-linear architecture instead of a simple feedforward linear architecture.</p><p>V1 actually sends out processed information to V2, V3, V4 and MT (a component related to memory processing) simultaneously. All other components continuously send feedback back to help correct the processing. The entire visual information flow is a continuous loop with multiple complex loops inside it. All of these contribute to correct object detection and recognition.</p><p>It can also explain why YOLO is not good at detecting small objects in local regions to a certain extent. Because YOLO lacks components like V3 that handles basic spatial information processes and keeps correcting the main processing stream. This is just my guess though. To investigate the real causes and solutions, I would need to learn more about how human’s visual system extracts depth information solely from visual inputs and how it can be implemented in ML.</p><h2 id=citation>Citation<a hidden class=anchor aria-hidden=true href=#citation>#</a></h2><p>Cited as:</p><blockquote><p>Diao, He. (Sep 2023). &ldquo;An Overview of Visual Cortex.&rdquo; Diaaaooo&rsquo;s Post:https://diaaaooo.github.io/posts/1-an-overview-of-visual-cortex/.</p></blockquote><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><p>[1] Ungerleider et al. “<a href=https://www.cns.nyu.edu/~tony/vns/readings/ungerleider-mishkin-1982.pdf>Two Cortical Visual Systems.</a>" NYU (1982)</p><p>[2] Serre et al. “<a href=https://www.pnas.org/doi/10.1073/pnas.0700622104>A feedforward architecture accounts for rapid categorization.</a>" PNAS PNAS:104(15)6424-6429 (2007)</p><p>[3] Wang et al. “<a href=https://arxiv.org/abs/1702.07800>On the Origin of Deep Learning.</a>" arVix preprint arXiv:1702.07800 (2017)</p><p>[4] Weng, Lilian. (Jun 2017). &ldquo;<a href=https://lilianweng.github.io/posts/2023-06-23-agent/>An Overview of Deep Learning for Curious People</a>&rdquo;. Lil’Log. <a href=https://lilianweng.github.io/posts/2023-06-23-agent/>https://lilianweng.github.io/posts/2023-06-23-agent/</a>.</p><p>[5] Kravitz et al. “<a href=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3532569/>The ventral visual pathway: An expanded neural framework for the processing of object quality.</a>" NCBI doi: 10.1016/j.tics.2012.10.011 (2014)</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://diaaaooo.github.io/tags/visual-cortex/>Visual Cortex</a></li><li><a href=https://diaaaooo.github.io/tags/computer-vision/>Computer Vision</a></li></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share An Overview of Visual Cortex on twitter" href="https://twitter.com/intent/tweet/?text=An%20Overview%20of%20Visual%20Cortex&amp;url=https%3a%2f%2fdiaaaooo.github.io%2fposts%2f1-an-overview-of-visual-cortex%2f1-an-overview-of-visual-cortex%2f&amp;hashtags=VisualCortex%2cComputerVision"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share An Overview of Visual Cortex on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fdiaaaooo.github.io%2fposts%2f1-an-overview-of-visual-cortex%2f1-an-overview-of-visual-cortex%2f&amp;title=An%20Overview%20of%20Visual%20Cortex&amp;summary=An%20Overview%20of%20Visual%20Cortex&amp;source=https%3a%2f%2fdiaaaooo.github.io%2fposts%2f1-an-overview-of-visual-cortex%2f1-an-overview-of-visual-cortex%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share An Overview of Visual Cortex on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fdiaaaooo.github.io%2fposts%2f1-an-overview-of-visual-cortex%2f1-an-overview-of-visual-cortex%2f&title=An%20Overview%20of%20Visual%20Cortex"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share An Overview of Visual Cortex on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fdiaaaooo.github.io%2fposts%2f1-an-overview-of-visual-cortex%2f1-an-overview-of-visual-cortex%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share An Overview of Visual Cortex on whatsapp" href="https://api.whatsapp.com/send?text=An%20Overview%20of%20Visual%20Cortex%20-%20https%3a%2f%2fdiaaaooo.github.io%2fposts%2f1-an-overview-of-visual-cortex%2f1-an-overview-of-visual-cortex%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share An Overview of Visual Cortex on telegram" href="https://telegram.me/share/url?text=An%20Overview%20of%20Visual%20Cortex&amp;url=https%3a%2f%2fdiaaaooo.github.io%2fposts%2f1-an-overview-of-visual-cortex%2f1-an-overview-of-visual-cortex%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share An Overview of Visual Cortex on ycombinator" href="https://news.ycombinator.com/submitlink?t=An%20Overview%20of%20Visual%20Cortex&u=https%3a%2f%2fdiaaaooo.github.io%2fposts%2f1-an-overview-of-visual-cortex%2f1-an-overview-of-visual-cortex%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://diaaaooo.github.io/>Diaaaooo's</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>